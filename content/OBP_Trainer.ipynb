{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd412aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# import open bandit pipeline (obp)\n",
    "import obp\n",
    "from obp.policy import (\n",
    "    IPWLearner, \n",
    "    QLearner,\n",
    "    NNPolicyLearner, \n",
    "    Random\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5b4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_output_file = './exp00000/result/out-1.txt' #need a double for slash before r (carriage return)\n",
    "item_feature_file = '../dataOFAiR/item-features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28826995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipw_train_learner(context,actions,max_iter=5000):\n",
    "    \n",
    "    # define NNPolicyLearner with IPW as its objective function\n",
    "    ipw_rf = IPWLearner(\n",
    "        n_actions=len(actions),\n",
    "        base_classifier = LogisticRegression(random_state=0,max_iter=5000,C=500).fit(context, actions)\n",
    "        \n",
    "        #base_classifier=RandomForest(\n",
    "        #n_estimators=30, min_samples_leaf=10, random_state=12345\n",
    "        #)\n",
    "    )\n",
    "\n",
    "\n",
    "    rewards = np.ones(len(context))\n",
    "\n",
    "    # train NNPolicyLearner on the training set of logged bandit data\n",
    "    ipw_rf.fit(\n",
    "        context=context,\n",
    "        action=actions,\n",
    "        reward=rewards\n",
    "    )\n",
    "    \n",
    "    return ipw_rf\n",
    "\n",
    "def agg_fnc(x):\n",
    "    d = []\n",
    "    d.append(','.join(map(str,x[\"itemID\"])))\n",
    "    d.append(','.join(map(str,x[\"rating\"])))\n",
    "    return pd.Series(d,index=[\"L\",\"L_rating\"])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23009715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       userID  itemID  rating\n",
       " 33549     671    8199     0.0\n",
       " 2099       42   36931     0.0\n",
       " 15199     304     889     0.0\n",
       " 27549     551     670     0.0\n",
       " 15249     305    9010     0.0,\n",
       " (33550, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read and process data\n",
    "df = pd.read_csv(reranked_output_file,header=None)#[:1000] #only reading the top 1000\n",
    "\n",
    "df_items = pd.read_csv(item_feature_file,header=None)\n",
    "df_items.columns = [\"itemID\",\"condition\",\"num\"]\n",
    "\n",
    "df.columns = ['userID','itemID','rating']\n",
    "df = df.sort_values(by=\"rating\")\n",
    "df.head(),df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bd13bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of uniques item ids\n",
    "len(df_items.itemID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce308f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create column of lists (L) and expand it into columns\n",
    "df_L = df.groupby('userID')[['itemID','rating']].apply(agg_fnc).reset_index()\n",
    "df_L2 = df_L['L'].str.split(\",\", expand=True)\n",
    "len_list = df_L2.shape[1];len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2a09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create action, position, and context\n",
    "# actions = itemID\n",
    "# posisiton = rank in list\n",
    "# context = userID\n",
    "df_L2_stack = df_L2.stack()\n",
    "df_L2_stack.name = \"action\"\n",
    "df_input = df_L2_stack.to_frame().reset_index(level=1).join(df_L[\"userID\"])\n",
    "df_input.columns = ['position','action','context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b99df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode itemID to use consecutive integers (reduces size of action matrix)\n",
    "\n",
    "item_encoder = LabelEncoder().fit(df_items['itemID'])\n",
    "\n",
    "df_input[\"action\"] = item_encoder.transform(df_input[\"action\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640eae0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This must be set to the max value of the itemIDs in the item dataset\n",
    "#max_actions =df_input['action'].astype(int).max() +1\n",
    "max_actions = np.max(item_encoder.transform(df_items['itemID'].astype(int))) + 1\n",
    "\n",
    "actions = df_input[\"action\"].astype(int).values.reshape(-1,)\n",
    "actions\n",
    "max_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fff3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NNPolicyLearner with IPW as its objective function\n",
    "ipw_rf = IPWLearner(\n",
    "    n_actions= int(max_actions),\n",
    "    base_classifier = RandomForest(n_estimators=1000,random_state=0),\n",
    "    len_list = len(df_input[\"position\"].unique())\n",
    "    )\n",
    "\n",
    "\n",
    "#Convert df_input field to input for the learner\n",
    "context = df_input[\"context\"].astype(int).values.reshape(-1,1)\n",
    "actions = df_input[\"action\"].astype(int).values.reshape(-1,)\n",
    "positions = df_input[\"position\"].astype(int).values.reshape(-1,)\n",
    "rewards = np.ones(df_input.shape[0])\n",
    "context.shape,actions.shape,rewards.shape,positions.shape\n",
    " \n",
    "#Train learner\n",
    "ipw_rf.fit(\n",
    "    context=context,\n",
    "    action=actions,\n",
    "    reward=rewards,\n",
    "    position=positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8e49af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 2830, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make prediction  - for testing\n",
    "all_users = np.unique(df_L[\"userID\"]).reshape(-1,1)\n",
    "results = ipw_rf.predict(context=all_users)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251bb254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2699, 2335, 2825, 2673, 1801, 2054,  553,   57, 2219, 2660, 1714,\n",
       "       2780, 1580, 1239, 1316, 2364, 2262, 2693, 1546,  266, 2581, 2450,\n",
       "       1613, 2192, 1152, 1786, 1945, 1464,  375,  536, 2629, 2129, 2097,\n",
       "       2101, 1242, 1539,  620, 1598,  902, 1551, 1996, 1719, 2441, 1576,\n",
       "       2276, 2244, 1973, 1724,  885,  777])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform results to list(L)\n",
    "results[0].T.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d920e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Learner\n",
    "rerank_dict = {}\n",
    "rerank_dict[\"OFAiR\"] = (ipw_rf,item_encoder)\n",
    "with open('OBP_Rerankers.pickle', 'wb') as f:\n",
    "    pickle.dump(rerank_dict, f)\n",
    "f.close()\n",
    "#To use joblib if necessary\n",
    "#filename = os.path.join('.', 'OBP_Rerankers.joblib')\n",
    "#joblib.dump(rerank_dict,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c7b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d891fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762972aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
