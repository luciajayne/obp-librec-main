{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09b6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# import open bandit pipeline (obp)\n",
    "import obp\n",
    "from obp.policy import (\n",
    "    IPWLearner, \n",
    "    QLearner,\n",
    "    NNPolicyLearner, \n",
    "    Random\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908a3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UIR_to_train(input_file,output_file):\n",
    "    df = pd.read_csv(input_file,header=None)[:1000]\n",
    "\n",
    "\n",
    "    df.columns = ['userID','itemID','rating']\n",
    "    df.shape\n",
    "\n",
    "\n",
    "\n",
    "    #df_L = df.groupby('user_id')[['item_id','rating']].apply(lambda list: ','.join(map(str,list)).strip())\n",
    "    df_L = df.groupby('userID')[['itemID','rating']].apply(agg_fnc).reset_index()\n",
    "\n",
    "    y = np.array(df_L.index.to_list())\n",
    "    X = np.array(df_L[\"userID\"]).reshape(-1,1)\n",
    "    # print(X,y)\n",
    "    ipw_learner =ipw_train_learner(X,y,10)\n",
    "    \n",
    "    \n",
    "    print(ipw_learner.predict(X).reshape(-1,df_L.shape[0]))\n",
    "    \n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump((ipw_learner,df_L), f)\n",
    "    f.close()\n",
    "    \n",
    "    return df_L, ipw_learner\n",
    "\n",
    "def ipw_train_learner(context,actions,max_iter=5000):\n",
    "    \n",
    "    # define NNPolicyLearner with IPW as its objective function\n",
    "    ipw_rf = IPWLearner(\n",
    "        n_actions=len(actions),\n",
    "        base_classifier = RandomForest(n_estimators=1000,random_state=0).fit(context, actions)\n",
    "        \n",
    "        #base_classifier=RandomForest(\n",
    "        #n_estimators=30, min_samples_leaf=10, random_state=12345\n",
    "        #)\n",
    "    )\n",
    "\n",
    "\n",
    "    rewards = np.ones(len(context))\n",
    "\n",
    "    # train NNPolicyLearner on the training set of logged bandit data\n",
    "    ipw_rf.fit(\n",
    "        context=context,\n",
    "        action=actions,\n",
    "        reward=rewards\n",
    "    )\n",
    "    \n",
    "    return ipw_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c53e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_fnc(x):\n",
    "    d = []\n",
    "    d.append(','.join(map(str,x[\"itemID\"])))\n",
    "    d.append(','.join(map(str,x[\"rating\"])))\n",
    "    return pd.Series(d,index=[\"L\",\"L_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d1491b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#demo01 uses re-ranking. This is the reason it was chose for demoOBP_FAIR. The results will be values that are reranked.\n",
    "input_file = 'demo01-out-1.txt' #change the name from librec-auto (out-1.txt) to (demo02-out-1.txt)\n",
    "output_file = 'IPW_OBP_demo01.pickle' #demo-2021 FAIR\n",
    "df_L1, learner1 = UIR_to_train(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demo02 has the algorithm and no re-ranking. \n",
    "input_file = 'demo02-out-1.txt' #change the name from librec-auto (out-1.txt) to (demo02-out-1.txt)\n",
    "output_file = 'IPW_OBP_demo02.pickle' #demo-2021 STANDARD\n",
    "df_L2, learner2= UIR_to_train(input_file,output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
